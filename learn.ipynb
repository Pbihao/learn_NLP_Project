{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>爱人之间来不得半点儿虚伪，一旦开始，就覆水难收。</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>觉得很平淡，在背景为导演是希区柯克的情况下。</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>一句话：难看到家了！！唯唯诺诺的讲，实在胆小鬼，那么何必要拍呢！！</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>王力宏很帅，这不太像是一部电影，像童话故事或者别的什么</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>嘛叫烂片，这就是。。。浪费时间，浪费钱，糟蹋演员，也折磨观众。。。</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>不错的喜剧片，彭导真的厉害啊，这片子各种奇妙的构思。</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>我也不知道看了点什么，印象中付辛博演娘炮演得还不错。</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>和 【我唾弃你的坟墓3】极度相似， 女主眼睛挺有特点的确实像个天使。</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>相信天堂的存在很幸福，会无惧死亡，还会见到以你幻想的样子出现的上帝。</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>最崩溃的是，昴星出场不到两分钟就双双挂了啊啊啊啊啊！！！</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text     label\n",
       "id                                               \n",
       "741            爱人之间来不得半点儿虚伪，一旦开始，就覆水难收。  positive\n",
       "145              觉得很平淡，在背景为导演是希区柯克的情况下。  negative\n",
       "221   一句话：难看到家了！！唯唯诺诺的讲，实在胆小鬼，那么何必要拍呢！！  negative\n",
       "215         王力宏很帅，这不太像是一部电影，像童话故事或者别的什么  negative\n",
       "177   嘛叫烂片，这就是。。。浪费时间，浪费钱，糟蹋演员，也折磨观众。。。  negative\n",
       "655          不错的喜剧片，彭导真的厉害啊，这片子各种奇妙的构思。  positive\n",
       "435          我也不知道看了点什么，印象中付辛博演娘炮演得还不错。  negative\n",
       "102  和 【我唾弃你的坟墓3】极度相似， 女主眼睛挺有特点的确实像个天使。  negative\n",
       "680  相信天堂的存在很幸福，会无惧死亡，还会见到以你幻想的样子出现的上帝。  positive\n",
       "133        最崩溃的是，昴星出场不到两分钟就双双挂了啊啊啊啊啊！！！  negative"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from main import *\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('./data/train_data.csv', index_col=0)\n",
    "label_denotation = {\n",
    "    1: 'positive',\n",
    "    0: 'negative'\n",
    "}\n",
    "train_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(830, 2) (170, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(train_data, test_size=0.17, random_state=12)\n",
    "print(train.shape, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "databunch = TextClasDataBunch.from_df(\".\", train, val,\n",
    "                  tokenizer=fastai_tokenizer,\n",
    "                  vocab=fastai_bert_vocab,\n",
    "                  include_bos=False,\n",
    "                  include_eos=False,\n",
    "                  text_cols=\"text\",\n",
    "                  label_cols='label',\n",
    "                  bs=config.bs,\n",
    "                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[CLS] 我 对 该 剧 组 的 化 妆 师 觉 得 很 好 奇 。 一 定 要 那 么 厚 的 粉 ？ 那 么 不 自 然 的 腮 红 ？ 明 明 有 些 场 景 很 漂 亮 。 苦 了 那 小 花 店 ~ [SEP]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] 不 禁 想 到 自 己 非 常 非 常 年 迈 时 会 怎 样 看 待 所 谓 生 命 的 意 义 和 这 一 生 的 旅 程 ， 是 否 还 有 力 量 改 变 ， 或 者 释 然 的 一 笑 。 [SEP]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] 女 主 真 是 尤 物 啊 ， 结 局 被 黑 色 幽 默 了 一 把 ， 和 整 部 片 子 的 冷 幽 默 基 调 一 致 ， 安 娜 卡 列 宁 娜 出 场 也 是 神 来 之 笔 哈 哈 [SEP]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] 有 乱 伦 来 降 低 师 生 恋 的 不 堪 ， 看 完 后 ， 果 真 是 三 观 尽 失 。 类 似 的 情 况 ， 男 主 像 英 雄 ， 儿 媳 像 婊 子 。 什 么 狗 屁 片 子 [SEP]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] 79 年 的 电 影 ， 纯 洁 的 心 灵 ， 纯 粹 的 精 神 。 看 腻 了 好 莱 坞 和 所 谓 的 国 产 大 片 ， 再 看 这 些 老 电 影 顿 时 觉 得 神 清 气 爽 。 [SEP]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "databunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.modeling import BertConfig, BertForSequenceClassification\n",
    "bert_model = BertForSequenceClassification.from_pretrained(config.bert_model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(databunch, bert_model, loss_func=loss_func, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (830 items)\n",
       "x: TextList\n",
       "[CLS] 故 事 真 的 没 有 一 点 儿 新 的 点 。 编 剧 可 是 邱 刚 健 啊 [UNK] [UNK] 剪 辑 也 挺 二 的 ， 废 戏 太 多 。 [SEP],[CLS] . . . . . . . . . . . . . . 为 毛 石 像 鬼 竟 然 是 天 使 啊 [SEP],[CLS] 史 诗 什 么 的 被 好 莱 坞 盯 上 一 般 都 是 稳 遭 毒 手 ， 一 颓 到 底 的 。 [SEP],[CLS] 为 什 么 那 时 候 的 车 戏 看 起 来 那 么 逼 真 ， 现 在 电 视 剧 里 车 上 的 玻 璃 外 面 明 显 是 贴 的 纸 [SEP],[CLS] 色 彩 饱 满 ， 非 洲 口 音 萌 萌 哒 ， 结 尾 那 个 无 厘 头 的 终 点 根 本 不 是 终 点 好 吗 ！ [SEP]\n",
       "y: CategoryList\n",
       "negative,negative,negative,positive,positive\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (170 items)\n",
       "x: TextList\n",
       "[CLS] 经 典 啊 ！ 我 初 中 看 电 视 播 了 片 段 就 记 忆 深 刻 了 [SEP],[CLS] 这 个 故 事 告 诉 我 们 ， 贼 可 以 爱 上 贼 ， 但 贵 妇 却 不 行 ～ [SEP],[CLS] 如 果 不 是 那 个 破 坏 别 人 婚 礼 现 场 的 糟 糕 的 结 尾 ， 这 其 实 是 一 部 还 不 错 的 片 子 。 [SEP],[CLS] 一 场 闹 剧 ， 又 不 好 笑 又 无 营 养 ， 菊 花 变 成 向 日 葵 [SEP],[CLS] 蓝 色 是 忧 郁 的 颜 色 ， 片 子 演 技 有 些 过 了 ， 没 看 完 ， 看 不 下 去 [SEP]\n",
       "y: CategoryList\n",
       "positive,positive,positive,negative,negative\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe300408a60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Embedding(21128, 768, padding_idx=0)\n",
       "  (1): Embedding(512, 768)\n",
       "  (2): Embedding(2, 768)\n",
       "  (3): BertLayerNorm()\n",
       "  (4): Dropout(p=0.1, inplace=False)\n",
       "  (5): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (6): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (7): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (8): Dropout(p=0.1, inplace=False)\n",
       "  (9): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (10): BertLayerNorm()\n",
       "  (11): Dropout(p=0.1, inplace=False)\n",
       "  (12): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (13): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (14): BertLayerNorm()\n",
       "  (15): Dropout(p=0.1, inplace=False)\n",
       "  (16): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (17): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (18): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (19): Dropout(p=0.1, inplace=False)\n",
       "  (20): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (21): BertLayerNorm()\n",
       "  (22): Dropout(p=0.1, inplace=False)\n",
       "  (23): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (24): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (25): BertLayerNorm()\n",
       "  (26): Dropout(p=0.1, inplace=False)\n",
       "  (27): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (28): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (29): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (30): Dropout(p=0.1, inplace=False)\n",
       "  (31): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (32): BertLayerNorm()\n",
       "  (33): Dropout(p=0.1, inplace=False)\n",
       "  (34): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (35): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (36): BertLayerNorm()\n",
       "  (37): Dropout(p=0.1, inplace=False)\n",
       "  (38): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (39): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (40): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (41): Dropout(p=0.1, inplace=False)\n",
       "  (42): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (43): BertLayerNorm()\n",
       "  (44): Dropout(p=0.1, inplace=False)\n",
       "  (45): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (46): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (47): BertLayerNorm()\n",
       "  (48): Dropout(p=0.1, inplace=False)\n",
       "  (49): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (50): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (51): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (52): Dropout(p=0.1, inplace=False)\n",
       "  (53): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (54): BertLayerNorm()\n",
       "  (55): Dropout(p=0.1, inplace=False)\n",
       "  (56): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (57): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (58): BertLayerNorm()\n",
       "  (59): Dropout(p=0.1, inplace=False)\n",
       "  (60): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (61): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (62): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (63): Dropout(p=0.1, inplace=False)\n",
       "  (64): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (65): BertLayerNorm()\n",
       "  (66): Dropout(p=0.1, inplace=False)\n",
       "  (67): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (68): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (69): BertLayerNorm()\n",
       "  (70): Dropout(p=0.1, inplace=False)\n",
       "  (71): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (72): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (73): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (74): Dropout(p=0.1, inplace=False)\n",
       "  (75): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (76): BertLayerNorm()\n",
       "  (77): Dropout(p=0.1, inplace=False)\n",
       "  (78): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (79): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (80): BertLayerNorm()\n",
       "  (81): Dropout(p=0.1, inplace=False)\n",
       "  (82): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (83): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (84): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (85): Dropout(p=0.1, inplace=False)\n",
       "  (86): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (87): BertLayerNorm()\n",
       "  (88): Dropout(p=0.1, inplace=False)\n",
       "  (89): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (90): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (91): BertLayerNorm()\n",
       "  (92): Dropout(p=0.1, inplace=False)\n",
       "  (93): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (94): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (95): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (96): Dropout(p=0.1, inplace=False)\n",
       "  (97): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (98): BertLayerNorm()\n",
       "  (99): Dropout(p=0.1, inplace=False)\n",
       "  (100): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (101): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (102): BertLayerNorm()\n",
       "  (103): Dropout(p=0.1, inplace=False)\n",
       "  (104): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (105): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (106): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (107): Dropout(p=0.1, inplace=False)\n",
       "  (108): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (109): BertLayerNorm()\n",
       "  (110): Dropout(p=0.1, inplace=False)\n",
       "  (111): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (112): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (113): BertLayerNorm()\n",
       "  (114): Dropout(p=0.1, inplace=False)\n",
       "  (115): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (116): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (117): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (118): Dropout(p=0.1, inplace=False)\n",
       "  (119): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (120): BertLayerNorm()\n",
       "  (121): Dropout(p=0.1, inplace=False)\n",
       "  (122): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (123): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (124): BertLayerNorm()\n",
       "  (125): Dropout(p=0.1, inplace=False)\n",
       "  (126): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (127): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (128): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (129): Dropout(p=0.1, inplace=False)\n",
       "  (130): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (131): BertLayerNorm()\n",
       "  (132): Dropout(p=0.1, inplace=False)\n",
       "  (133): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (134): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (135): BertLayerNorm()\n",
       "  (136): Dropout(p=0.1, inplace=False)\n",
       "  (137): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (138): Tanh()\n",
       "  (139): Dropout(p=0.1, inplace=False)\n",
       "  (140): Linear(in_features=768, out_features=2, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.load(\"./stage1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9715, 0.0285])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict(\"设施老化，紧靠马路噪音太大，晚上楼上卫生间的水流声和空调噪音非常大，无法入眠\")[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (learn_nlp)",
   "language": "python",
   "name": "pycharm-e5c5c361"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
